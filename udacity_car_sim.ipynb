{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u2NesD9Rtll165DzzIa1Vvp8xbttKJ3d",
      "authorship_tag": "ABX9TyMXcyMaaHGMpoCcPSD+SVf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omar61554/FAI_autonomous-car/blob/master/udacity_car_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary libraries and mounting Google Drive (if needed)"
      ],
      "metadata": {
        "id": "SE1lBrxKoe9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "c6mmh2SRnOZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ca1ed4-26c0-4e0a-cf0a-4db7d0e0f5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "# Mount Google Drive (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CNN model architecture"
      ],
      "metadata": {
        "id": "ZQuUv97PokOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, kernel_size=5, stride=2, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(36, 48, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(64 * 6 * 6, 96)\n",
        "        self.fc2 = nn.Linear(96, 100)\n",
        "\n",
        "        # Linear regression branch\n",
        "        self.linear_regression = nn.Linear(100, 96)\n",
        "\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "        self.fc4 = nn.Linear(10, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, channels, height, width = x.size()\n",
        "\n",
        "        # Process input through convolutional layers\n",
        "        x = x.view(batch_size * seq_len, channels, height, width)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Calculate the appropriate padding manually\n",
        "        padding_height = (x.size(-2) - 1) // 2\n",
        "        padding_width = (x.size(-1) - 1) // 2\n",
        "        self.linear_regression = nn.Conv2d(64, 1024, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Continue with the original path\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        # Reshape back to the original sequence length\n",
        "        x = x.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return x, x"
      ],
      "metadata": {
        "id": "iE7DfhHZokh9"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the custom dataset class"
      ],
      "metadata": {
        "id": "xRcwdfCbonuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = []\n",
        "        with open(data_path, 'r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            for line in reader:\n",
        "                image_paths = line[:3]  # Extract the first three values as image paths\n",
        "                label = float(line[6])  # Extract the last value as the label\n",
        "                self.data.append({'image_path': image_paths, 'label': label})\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, index):\n",
        "      image_paths = self.data[index]['image_path']\n",
        "      images = []\n",
        "\n",
        "      for image_path in image_paths:\n",
        "          image = cv2.imread(os.path.join(data_path, image_path))\n",
        "          if image is not None:\n",
        "              images.append(image)\n",
        "          else:\n",
        "\n",
        "              images.append(np.zeros((160, 320, 3), dtype=np.uint8))\n",
        "\n",
        "      angle = torch.tensor(self.data[index]['label'], dtype=torch.float32)\n",
        "\n",
        "     # Apply transformations if specified\n",
        "      if self.transform:\n",
        "        images = [self.transform(image) for image in images]\n",
        "        if len(images) < 3:\n",
        "\n",
        "            images.extend([torch.zeros_like(images[0])] * (3 - len(images)))\n",
        "        images = torch.stack(images).float()  # Convert the list of tensors to a single tensor\n",
        "         # Reshape and expand dimensions of the angle tensor\n",
        "        angle = angle.view(-1, 1, 1).expand(-1, 3, 1)\n",
        "        return images, angle\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "WKSMux0iosLM"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load and preprocess the data"
      ],
      "metadata": {
        "id": "_JSqikKMpMrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to data\n",
        "data_path = '/content/drive/MyDrive/sim data/data/driving_log.csv'\n",
        "\n",
        "\n",
        "# Define the ratio for splitting the data into test and validation sets\n",
        "test_ratio = 0.2  # 20% of the data will be used for testing\n",
        "\n",
        "# Create the dataset\n",
        "transform = ToTensor()  # Add any other transformations if needed\n",
        "dataset = CustomDataset(data_path, transform=transform)\n",
        "\n",
        "# Calculate the number of samples for the test and validation sets\n",
        "num_samples = len(dataset)\n",
        "num_test_samples = int(test_ratio * num_samples)\n",
        "num_val_samples = num_samples - num_test_samples\n",
        "\n",
        "# Split the dataset into test and validation sets\n",
        "test_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_test_samples, num_val_samples])\n",
        "\n",
        "# Create the data loaders\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LCCID1gHpTIf"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model, define the loss function and optimizer"
      ],
      "metadata": {
        "id": "nBnq_QB7pVWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = CNNModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "jLSjQLd_pX4h"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "Byt91E2apZR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, angles in train_loader:\n",
        "        images = images.to(device)\n",
        "        angles = angles.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, mapped_outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, angles)\n",
        "        mapped_loss = criterion(mapped_outputs, angles)\n",
        "        total_loss = loss + mapped_loss\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += total_loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1} - Training Loss: {epoch_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz1N71A3pa3Y",
        "outputId": "4469f2e8-afc3-423c-9fd0-177185d745bf"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Training Loss: 359.4897592166528\n",
            "Epoch 2 - Training Loss: 11.588416777105435\n",
            "Epoch 3 - Training Loss: 10.101915077562817\n",
            "Epoch 4 - Training Loss: 10.93315867124434\n",
            "Epoch 5 - Training Loss: 10.0560758115654\n",
            "Epoch 6 - Training Loss: 11.36872775524663\n",
            "Epoch 7 - Training Loss: 12.075332904832168\n",
            "Epoch 8 - Training Loss: 12.188220989855534\n",
            "Epoch 9 - Training Loss: 11.312747571278702\n",
            "Epoch 10 - Training Loss: 11.016983746386627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on validation set"
      ],
      "metadata": {
        "id": "OR3N88iOaU8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "val_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, angles in val_loader:\n",
        "        images = images.to(device)\n",
        "        angles = angles.to(device)\n",
        "        # Reshape the target tensor to match the input size\n",
        "        angles = angles.view(angles.size(0), angles.size(2), angles.size(3))\n",
        "        outputs, _ = model(images)\n",
        "        loss = criterion(outputs, angles)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Validation Loss: {avg_val_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vyMfOnaWiB",
        "outputId": "dccce306-ef02-4f8d-9ad6-022726f72226"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.8459620624780655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on the test set"
      ],
      "metadata": {
        "id": "bnRb_FFUpcEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, angles in test_loader:\n",
        "        images = images.to(device)\n",
        "        angles = angles.to(device)\n",
        "        # Reshape the target tensor to match the input size\n",
        "        angles = angles.view(angles.size(0), angles.size(2), angles.size(3))\n",
        "        outputs, _ = model(images)\n",
        "        loss = criterion(outputs, angles)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "print(f\"Test Loss: {test_loss / len(test_loader)}\")"
      ],
      "metadata": {
        "id": "uWvW-30wpdvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45511911-ff83-4767-8ab5-8d4fe86a0d5f"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 7.86317600607872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained model"
      ],
      "metadata": {
        "id": "ujAWaDv1pfe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'model.pthT1')"
      ],
      "metadata": {
        "id": "cMBq1N1nphh6"
      },
      "execution_count": 218,
      "outputs": []
    }
  ]
}